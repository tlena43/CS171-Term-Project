{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7961b32a-825b-4797-bb54-bc3a0aae2756",
   "metadata": {},
   "source": [
    "# CS171 Project — Data Preparation \n",
    "\n",
    "## E-Waste Image Dataset\n",
    "\n",
    "**Course:** CS 171 — Introduction to Machine Learning  \n",
    "**Name:** Samriddhi Matharu  \n",
    "**Student ID:** 016328156  \n",
    "\n",
    "**Dataset Name:** E-Waste Image Dataset  \n",
    "**Source:** [Kaggle — E-Waste Image Dataset](https://www.kaggle.com/datasets/akshat103/e-waste-image-dataset/data)  \n",
    "**License:** Apache 2.0  \n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "This dataset contains approximately **3,000 images** of common electronic waste items, organized into **10 categories** such as batteries, circuit boards, televisions, and mobile devices.  \n",
    "Images are pre-labeled and stored in separate folders for training and testing. This is in aim to determine how computer vision can support real-world waste management pipelines. This work demonstrates the role of machine learning in promoting sustainability and reducing landfill impact.\n",
    "\n",
    "---\n",
    "\n",
    "### Objective \n",
    "The goal is to build a **Convolutional Neural Network (CNN)** that can classify images of e-waste into their respective categories.  \n",
    "This will serve as part of a broader project on **machine learning for waste processing and recycling**.  \n",
    "The primary task for now is **image classification**.\n",
    "\n",
    "---\n",
    "\n",
    "### Planned Data Preparation\n",
    "This notebook prepares the e-waste image dataset for modeling.\n",
    "\n",
    "Steps:\n",
    "- Load dataset using `torchvision.datasets.ImageFolder`.  \n",
    "- Inspect the Kaggle `train`, `val`, and `test` folders.\n",
    "- Merge Kaggle’s `val` split into the `test` split to create one larger test set.\n",
    "- Summarize per-class image counts after merging.\n",
    "- Load and summarize an additional **hand-curated validation set** (`val (by hand)`) of real-world images collected from the web.\n",
    "\n",
    "The modeling and training code live in a separate notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d27b3-d0a4-44a5-942b-ea9f8defc54c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afc1417-06fd-471b-8261-7364885e0735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import shutil\n",
    "import stat\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cfc40-502a-43c6-bf4a-9a6cde9398f7",
   "metadata": {},
   "source": [
    "## 1. Inspect Kaggles original `train`, `val`, and `test` splits\n",
    "\n",
    "The Kaggle E-Waste dataset comes pre-split into:\n",
    "- `data/train`\n",
    "- `data/val`\n",
    "- `data/test`\n",
    "\n",
    "Before changing anything, we:\n",
    "- List the class names in each split.\n",
    "- Count how many images exist per class and per split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d0fd5e-b4c5-4030-b754-e4906b8df09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classes per split ===\n",
      "train: ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "val  : ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "test : ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "\n",
      "=== TRAIN per-class counts ===\n",
      "         Battery: 240\n",
      "        Keyboard: 240\n",
      "       Microwave: 240\n",
      "          Mobile: 240\n",
      "           Mouse: 240\n",
      "             PCB: 240\n",
      "          Player: 240\n",
      "         Printer: 240\n",
      "      Television: 240\n",
      " Washing Machine: 240\n",
      "Total in train: 2400\n",
      "\n",
      "=== VAL per-class counts ===\n",
      "         Battery: 30\n",
      "        Keyboard: 30\n",
      "       Microwave: 30\n",
      "          Mobile: 30\n",
      "           Mouse: 30\n",
      "             PCB: 30\n",
      "          Player: 30\n",
      "         Printer: 30\n",
      "      Television: 30\n",
      " Washing Machine: 30\n",
      "Total in val: 300\n",
      "\n",
      "=== TEST per-class counts ===\n",
      "         Battery: 30\n",
      "        Keyboard: 30\n",
      "       Microwave: 30\n",
      "          Mobile: 30\n",
      "           Mouse: 30\n",
      "             PCB: 30\n",
      "          Player: 30\n",
      "         Printer: 30\n",
      "      Television: 30\n",
      " Washing Machine: 30\n",
      "Total in test: 300\n"
     ]
    }
   ],
   "source": [
    "# Config & helper functions ===\n",
    "BASE_DIR = \"data\"\n",
    "SPLITS   = [\"train\", \"val\", \"test\"] #given by kaggle \n",
    "\n",
    "def sp(split: str) -> str:\n",
    "    \"\"\"Return the full path for a split under BASE_DIR.\"\"\"\n",
    "    return os.path.join(BASE_DIR, split)\n",
    "\n",
    "def list_classes(split: str):\n",
    "    \"\"\"List class folders inside a split\"\"\"\n",
    "    p = sp(split)\n",
    "    if not os.path.exists(p):\n",
    "        return []\n",
    "    return sorted(\n",
    "        d for d in os.listdir(p)\n",
    "        if os.path.isdir(os.path.join(p, d))\n",
    "    )\n",
    "\n",
    "def count_images(split: str):\n",
    "    \"\"\"Count number of image files per class in a given split.\"\"\"\n",
    "    p = sp(split)\n",
    "    counts = {}\n",
    "    if not os.path.exists(p):\n",
    "        return counts\n",
    "\n",
    "    for cls in list_classes(split):\n",
    "        cls_path = os.path.join(p, cls)\n",
    "        counts[cls] = sum(\n",
    "            1 for f in os.listdir(cls_path)\n",
    "            if os.path.isfile(os.path.join(cls_path, f))\n",
    "        )\n",
    "    return counts\n",
    "\n",
    "def summarize(split: str):\n",
    "    \"\"\"Pretty-print per-class counts for one split.\"\"\"\n",
    "    counts = count_images(split)\n",
    "    if not counts:\n",
    "        print(f\"[info] '{split}' not found or empty.\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"\\n=== {split.upper()} per-class counts ===\")\n",
    "    for cls, n in counts.items():\n",
    "        print(f\"{cls:>16}: {n}\")\n",
    "    total = sum(counts.values())\n",
    "    print(f\"Total in {split}: {total}\")\n",
    "    return total\n",
    "\n",
    "def summarize_all():\n",
    "    \"\"\"Summarize all splits (train/val/test).\"\"\"\n",
    "    print(\"\\n=== Classes per split ===\")\n",
    "    for s in SPLITS:\n",
    "        print(f\"{s:<5}: {list_classes(s) or '—'}\")\n",
    "    totals = {s: summarize(s) for s in SPLITS}\n",
    "    return totals\n",
    "\n",
    "# Initial summary before any changes\n",
    "_ = summarize_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9db2c-60ae-4631-b977-3e33e7b80815",
   "metadata": {},
   "source": [
    "## 2. Merge Kaggle `val` into `test` to create one big test folder \n",
    "\n",
    "For this project, we follow the professor’s guidance:\n",
    "\n",
    "- Use **all original Kaggle `train` images** for training.\n",
    "- Combine Kaggle `val` and `test` into **one larger test set**.\n",
    "- Later, use a **separate hand-curated validation set** of real-world images (outside Kaggle).\n",
    "\n",
    "Below, I move all images from `data/val/*` into `data/test/*` (class-by-class) and then remove the now-empty `val` folder. The function is written to be **idempotent**: if you run it again, it won’t duplicate files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27870ae4-3479-44b6-9a88-732ced784ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Merged (moved) 300 files from 'val' → 'test' and removed 'val/'.\n",
      "\n",
      "=== Classes per split ===\n",
      "train: ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "val  : —\n",
      "test : ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "\n",
      "=== TRAIN per-class counts ===\n",
      "         Battery: 240\n",
      "        Keyboard: 240\n",
      "       Microwave: 240\n",
      "          Mobile: 240\n",
      "           Mouse: 240\n",
      "             PCB: 240\n",
      "          Player: 240\n",
      "         Printer: 240\n",
      "      Television: 240\n",
      " Washing Machine: 240\n",
      "Total in train: 2400\n",
      "[info] 'val' not found or empty.\n",
      "\n",
      "=== TEST per-class counts ===\n",
      "         Battery: 60\n",
      "        Keyboard: 60\n",
      "       Microwave: 60\n",
      "          Mobile: 60\n",
      "           Mouse: 60\n",
      "             PCB: 60\n",
      "          Player: 60\n",
      "         Printer: 60\n",
      "      Television: 60\n",
      " Washing Machine: 60\n",
      "Total in test: 600\n"
     ]
    }
   ],
   "source": [
    "# One-time merge: move val -> test \n",
    "\n",
    "def _force_writable(func, path, exc_info):\n",
    "    \"\"\"\n",
    "    Helper for shutil.rmtree on Windows:\n",
    "    Make read-only files writable, then retry.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.chmod(path, stat.S_IWRITE)\n",
    "    except Exception:\n",
    "        pass\n",
    "    func(path)\n",
    "\n",
    "def merge_val_into_test_once():\n",
    "    val_root, test_root = sp(\"val\"), sp(\"test\")\n",
    "\n",
    "    if not os.path.exists(val_root):\n",
    "        print(\"[skip] 'val' folder not present. Nothing to merge.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(test_root, exist_ok=True)\n",
    "    transferred = 0\n",
    "\n",
    "    # Move files class-by-class\n",
    "    for cls in list_classes(\"val\"):\n",
    "        src_cls = os.path.join(val_root, cls)\n",
    "        if not os.path.isdir(src_cls):\n",
    "            continue\n",
    "\n",
    "        dst_cls = os.path.join(test_root, cls)\n",
    "        os.makedirs(dst_cls, exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(src_cls):\n",
    "            src = os.path.join(src_cls, fname)\n",
    "            if not os.path.isfile(src):\n",
    "                continue\n",
    "\n",
    "            dst = os.path.join(dst_cls, fname)\n",
    "            # Skip if file already exists in test\n",
    "            if os.path.exists(dst):\n",
    "                continue\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "            transferred += 1\n",
    "\n",
    "    # Remove 'val' folder (and any empty subfolders) once everything is moved\n",
    "    try:\n",
    "        shutil.rmtree(val_root, onerror=_force_writable)\n",
    "        print(f\"[done] Merged (moved) {transferred} files from 'val' → 'test' and removed 'val/'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Could not completely remove 'val': {e}. You can delete it manually if needed.\")\n",
    "\n",
    "# Run the merge (only meaningful the first time)\n",
    "merge_val_into_test_once()\n",
    "\n",
    "# Re-summarize after merging\n",
    "_ = summarize_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b15da-ff4a-4301-92d2-fed823b455a5",
   "metadata": {},
   "source": [
    "## 3. Hand-Curated Validation Set (`val (by hand)`)\n",
    "\n",
    "To test how well the model generalizes beyond curated Kaggle images,  \n",
    "we created a **separate folder**:\n",
    "\n",
    "- `data/val (by hand)/Battery/`\n",
    "- `data/val (by hand)/Keyboard/`\n",
    "- ...\n",
    "- `data/val (by hand)/Washing Machine/`\n",
    "\n",
    "Each subfolder contains ~10 real-world images per class collected from the web  \n",
    "(e.g., product photos, different backgrounds, lighting, viewpoints).\n",
    "\n",
    "Below, we:\n",
    "- Define a transform consistent with the CNN input size (128×128).\n",
    "- Load this hand-curated validation set with `ImageFolder`.\n",
    "- Print the class names and the number of valid image files per class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017d9f97-ed4c-42fc-96b1-39b02e4a0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in hand-curated val set: ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
      "Total images in val (by hand): 108\n",
      "\n",
      "=== Per-class counts in 'val (by hand)' ===\n",
      "         Battery: 10 image files\n",
      "        Keyboard: 10 image files\n",
      "       Microwave: 10 image files\n",
      "          Mobile: 10 image files\n",
      "           Mouse: 10 image files\n",
      "             PCB: 10 image files\n",
      "          Player: 10 image files\n",
      "         Printer: 10 image files\n",
      "      Television: 10 image files\n",
      " Washing Machine: 10 image files\n"
     ]
    }
   ],
   "source": [
    "# Hand-curated validation set: data/val (by hand) \n",
    "\n",
    "val_byhand_dir = \"data/val (by hand)\"   # folder created manually\n",
    "\n",
    "IMG_SIZE_V3 = 128\n",
    "\n",
    "val_transform_v3 = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE_V3, IMG_SIZE_V3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                         [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Dataset + loader for the hand-curated validation set\n",
    "val_byhand_ds = datasets.ImageFolder(root=val_byhand_dir,\n",
    "                                     transform=val_transform_v3)\n",
    "val_byhand_loader = DataLoader(val_byhand_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classes in hand-curated val set:\", val_byhand_ds.classes)\n",
    "print(\"Total images in val (by hand):\", len(val_byhand_ds))\n",
    "\n",
    "# Optional: per-class image counts (only valid image extensions)\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "print(\"\\n=== Per-class counts in 'val (by hand)' ===\")\n",
    "for cls in sorted(os.listdir(val_byhand_dir)):\n",
    "    cls_path = os.path.join(val_byhand_dir, cls)\n",
    "    if os.path.isdir(cls_path):\n",
    "        imgs = [\n",
    "            f for f in os.listdir(cls_path)\n",
    "            if os.path.splitext(f)[1].lower() in valid_exts\n",
    "        ]\n",
    "        print(f\"{cls:>16}: {len(imgs)} image files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202608d-e8e1-4765-ad1c-ecac8ad228ed",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "After running this notebook:\n",
    "\n",
    "- `data/train/` contains the Kaggle training images (10 e-waste classes).\n",
    "- `data/test/` contains the original Kaggle test images **plus** the merged Kaggle validation images.\n",
    "- `data/val (by hand)/` contains real-world images collected manually, one folder per class.\n",
    "\n",
    "These prepared splits are now ready to be used in the main modeling notebook  \n",
    "(e.g., `02_modeling_ewaste.ipynb`), where I train:\n",
    "\n",
    "- A custom CNN (Model V3), and  \n",
    "- A pretrained ResNet-18 (Model V4),\n",
    "\n",
    "and compare their performance both on Kaggle data and the hand-curated validation set.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs171",
   "language": "python",
   "name": "cs171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
